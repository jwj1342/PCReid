[   15    16    17 ... 10800 10801 10802]
query
[[     1    284    307    503      4]
 [     1    308    331    503      4]
 [     1    332    355    503      4]
 ...
 [     1 230668 230691    937      8]
 [     1 230692 230715    937      8]
 [     1 230716 230739    937      8]]
gallery
[[     2      1     24    503      3]
 [     2     25     48    503      3]
 [     2     49     72    503      3]
 ...
 [     2 230355 230378    937      7]
 [     2 230379 230402    937      7]
 [     2 230403 230405    937      7]]
[   15    16    17 ... 10800 10801 10802]
pid_list
[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 402, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502]
{1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 8: 7, 9: 8, 10: 9, 11: 10, 12: 11, 13: 12, 14: 13, 15: 14, 16: 15, 17: 16, 18: 17, 19: 18, 20: 19, 21: 20, 22: 21, 23: 22, 24: 23, 25: 24, 26: 25, 27: 26, 28: 27, 29: 28, 30: 29, 31: 30, 32: 31, 33: 32, 34: 33, 35: 34, 36: 35, 37: 36, 38: 37, 39: 38, 40: 39, 41: 40, 42: 41, 43: 42, 44: 43, 45: 44, 46: 45, 47: 46, 48: 47, 49: 48, 50: 49, 51: 50, 52: 51, 53: 52, 54: 53, 55: 54, 56: 55, 57: 56, 58: 57, 59: 58, 60: 59, 61: 60, 62: 61, 63: 62, 64: 63, 65: 64, 66: 65, 67: 66, 68: 67, 69: 68, 70: 69, 71: 70, 72: 71, 73: 72, 74: 73, 75: 74, 76: 75, 77: 76, 78: 77, 79: 78, 80: 79, 81: 80, 82: 81, 83: 82, 84: 83, 85: 84, 86: 85, 87: 86, 88: 87, 89: 88, 90: 89, 91: 90, 92: 91, 93: 92, 94: 93, 95: 94, 96: 95, 97: 96, 98: 97, 99: 98, 100: 99, 101: 100, 102: 101, 103: 102, 104: 103, 105: 104, 106: 105, 107: 106, 108: 107, 109: 108, 110: 109, 111: 110, 112: 111, 113: 112, 114: 113, 115: 114, 116: 115, 117: 116, 118: 117, 119: 118, 120: 119, 121: 120, 122: 121, 123: 122, 124: 123, 125: 124, 126: 125, 127: 126, 128: 127, 129: 128, 130: 129, 131: 130, 132: 131, 133: 132, 134: 133, 135: 134, 136: 135, 137: 136, 138: 137, 139: 138, 140: 139, 141: 140, 142: 141, 143: 142, 144: 143, 145: 144, 146: 145, 147: 146, 148: 147, 149: 148, 150: 149, 151: 150, 152: 151, 153: 152, 154: 153, 155: 154, 156: 155, 157: 156, 158: 157, 159: 158, 160: 159, 161: 160, 162: 161, 163: 162, 164: 163, 165: 164, 166: 165, 167: 166, 168: 167, 169: 168, 170: 169, 171: 170, 172: 171, 173: 172, 174: 173, 175: 174, 176: 175, 177: 176, 178: 177, 179: 178, 180: 179, 181: 180, 182: 181, 183: 182, 184: 183, 185: 184, 186: 185, 187: 186, 188: 187, 189: 188, 190: 189, 191: 190, 192: 191, 193: 192, 194: 193, 195: 194, 196: 195, 197: 196, 198: 197, 199: 198, 200: 199, 201: 200, 202: 201, 203: 202, 204: 203, 205: 204, 206: 205, 207: 206, 208: 207, 209: 208, 210: 209, 211: 210, 212: 211, 213: 212, 214: 213, 215: 214, 216: 215, 217: 216, 218: 217, 219: 218, 220: 219, 221: 220, 222: 221, 223: 222, 224: 223, 225: 224, 226: 225, 227: 226, 228: 227, 229: 228, 230: 229, 231: 230, 232: 231, 233: 232, 234: 233, 235: 234, 236: 235, 237: 236, 238: 237, 239: 238, 240: 239, 241: 240, 242: 241, 243: 242, 244: 243, 245: 244, 246: 245, 247: 246, 248: 247, 249: 248, 250: 249, 251: 250, 252: 251, 253: 252, 254: 253, 255: 254, 256: 255, 257: 256, 258: 257, 259: 258, 260: 259, 261: 260, 262: 261, 263: 262, 264: 263, 265: 264, 266: 265, 267: 266, 268: 267, 269: 268, 270: 269, 271: 270, 272: 271, 273: 272, 274: 273, 275: 274, 276: 275, 277: 276, 278: 277, 279: 278, 280: 279, 281: 280, 282: 281, 283: 282, 284: 283, 285: 284, 286: 285, 287: 286, 288: 287, 289: 288, 290: 289, 291: 290, 292: 291, 293: 292, 294: 293, 295: 294, 296: 295, 297: 296, 298: 297, 299: 298, 300: 299, 301: 300, 302: 301, 303: 302, 304: 303, 305: 304, 306: 305, 307: 306, 308: 307, 309: 308, 310: 309, 311: 310, 312: 311, 313: 312, 314: 313, 315: 314, 316: 315, 317: 316, 318: 317, 319: 318, 320: 319, 321: 320, 322: 321, 323: 322, 324: 323, 325: 324, 326: 325, 327: 326, 328: 327, 329: 328, 330: 329, 331: 330, 332: 331, 333: 332, 334: 333, 335: 334, 336: 335, 337: 336, 338: 337, 339: 338, 340: 339, 341: 340, 342: 341, 343: 342, 344: 343, 345: 344, 346: 345, 347: 346, 348: 347, 349: 348, 350: 349, 351: 350, 352: 351, 353: 352, 354: 353, 355: 354, 356: 355, 357: 356, 358: 357, 359: 358, 360: 359, 361: 360, 362: 361, 363: 362, 364: 363, 365: 364, 366: 365, 367: 366, 368: 367, 369: 368, 370: 369, 371: 370, 372: 371, 373: 372, 374: 373, 375: 374, 376: 375, 377: 376, 378: 377, 379: 378, 380: 379, 381: 380, 382: 381, 383: 382, 384: 383, 385: 384, 386: 385, 387: 386, 388: 387, 389: 388, 390: 389, 391: 390, 392: 391, 393: 392, 394: 393, 395: 394, 396: 395, 397: 396, 398: 397, 400: 398, 401: 399, 402: 400, 403: 401, 405: 402, 406: 403, 407: 404, 408: 405, 409: 406, 410: 407, 411: 408, 412: 409, 413: 410, 414: 411, 415: 412, 416: 413, 417: 414, 418: 415, 419: 416, 420: 417, 421: 418, 422: 419, 423: 420, 424: 421, 425: 422, 426: 423, 427: 424, 428: 425, 429: 426, 430: 427, 431: 428, 432: 429, 433: 430, 434: 431, 435: 432, 436: 433, 437: 434, 438: 435, 439: 436, 440: 437, 441: 438, 442: 439, 443: 440, 444: 441, 445: 442, 446: 443, 447: 444, 448: 445, 449: 446, 450: 447, 451: 448, 452: 449, 453: 450, 454: 451, 455: 452, 456: 453, 457: 454, 458: 455, 459: 456, 460: 457, 461: 458, 462: 459, 463: 460, 464: 461, 465: 462, 466: 463, 467: 464, 468: 465, 469: 466, 470: 467, 471: 468, 472: 469, 473: 470, 474: 471, 475: 472, 476: 473, 477: 474, 478: 475, 479: 476, 480: 477, 481: 478, 482: 479, 483: 480, 484: 481, 485: 482, 486: 483, 487: 484, 488: 485, 489: 486, 490: 487, 491: 488, 492: 489, 493: 490, 494: 491, 495: 492, 496: 493, 497: 494, 498: 495, 499: 496, 500: 497, 501: 498, 502: 499}
=> VCM loaded
Dataset statistics:
---------------------------------
subset      | # ids | # tracklets
---------------------------------
train_ir    |   500 |     4291
train_rgb   |   500 |     5460
query       |   427 |     4584
gallery     |   427 |     5099
---------------------------------
wandb: Currently logged in as: jwj1342. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.16.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in /root/autodl-tmp/experiment/PCReid/wandb/run-20240308_092735-9er94i1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-blaze-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jwj1342/PoseReid
wandb: üöÄ View run at https://wandb.ai/jwj1342/PoseReid/runs/9er94i1t
ir_label    | [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499]
rgb_label   | [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269
 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287
 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305
 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323
 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341
 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359
 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377
 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395
 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413
 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431
 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449
 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467
 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485
 486 487 488 489 490 491 492 493 494 495 496 497 498 499]
Epoch: [0][20/268]	Avg Loss 41.4800 Loss_id 6.5187 Loss_tri 27.6123 Time 28.27 seconds
Epoch: [0][40/268]	Avg Loss 37.5797 Loss_id 6.5096 Loss_tri 34.0375 Time 22.12 seconds
Epoch: [0][60/268]	Avg Loss 36.7242 Loss_id 6.5252 Loss_tri 25.6163 Time 22.23 seconds
Epoch: [0][80/268]	Avg Loss 31.7961 Loss_id 6.3058 Loss_tri 24.4774 Time 22.17 seconds
Epoch: [0][100/268]	Avg Loss 30.5019 Loss_id 6.5092 Loss_tri 29.0314 Time 22.19 seconds
Epoch: [0][120/268]	Avg Loss 26.8607 Loss_id 6.4911 Loss_tri 18.1034 Time 22.25 seconds
Epoch: [0][140/268]	Avg Loss 21.7882 Loss_id 6.4711 Loss_tri 11.4312 Time 22.22 seconds
Epoch: [0][160/268]	Avg Loss 16.7128 Loss_id 6.4520 Loss_tri 8.0850 Time 22.24 seconds
Epoch: [0][180/268]	Avg Loss 12.0562 Loss_id 6.4570 Loss_tri 4.6664 Time 22.17 seconds
Epoch: [0][200/268]	Avg Loss 10.0467 Loss_id 6.5084 Loss_tri 3.4917 Time 22.20 seconds
Epoch: [0][220/268]	Avg Loss 8.9964 Loss_id 6.4800 Loss_tri 1.7025 Time 22.25 seconds
Epoch: [0][240/268]	Avg Loss 8.3167 Loss_id 6.4444 Loss_tri 1.9197 Time 22.29 seconds
Epoch: [0][260/268]	Avg Loss 8.1357 Loss_id 6.4970 Loss_tri 1.1279 Time 22.22 seconds
Extracting Gallery Feature...
Extracting Query Feature...
Computing CMC and mAP
Results ----------
testmAP: 1.2%
CMC curve
Rank-1  : 2.0%
Rank-5  : 6.5%
Rank-10 : 10.3%
Rank-20 : 16.3%
------------------
Extracting Gallery Feature...
Extracting Query Feature...
Computing CMC and mAP
Results ----------
testmAP: 1.3%
CMC curve
Rank-1  : 1.9%
Rank-5  : 7.3%
Rank-10 : 11.6%
Rank-20 : 18.0%
------------------
Epoch: [1][20/268]	Avg Loss 8.2251 Loss_id 6.4823 Loss_tri 1.5235 Time 28.20 seconds
Epoch: [1][40/268]	Avg Loss 7.7262 Loss_id 6.4654 Loss_tri 1.3832 Time 22.14 seconds
Epoch: [1][60/268]	Avg Loss 7.6034 Loss_id 6.4498 Loss_tri 1.1451 Time 22.18 seconds
Epoch: [1][80/268]	Avg Loss 7.4662 Loss_id 6.3541 Loss_tri 1.2451 Time 22.23 seconds
Epoch: [1][100/268]	Avg Loss 7.3964 Loss_id 6.4190 Loss_tri 1.2398 Time 22.20 seconds
Epoch: [1][120/268]	Avg Loss 7.3954 Loss_id 6.4161 Loss_tri 0.9608 Time 22.17 seconds
Epoch: [1][140/268]	Avg Loss 7.2289 Loss_id 6.4684 Loss_tri 0.6738 Time 22.17 seconds
Epoch: [1][160/268]	Avg Loss 7.3262 Loss_id 6.3868 Loss_tri 1.0576 Time 22.16 seconds
Epoch: [1][180/268]	Avg Loss 7.2545 Loss_id 6.4449 Loss_tri 0.6739 Time 22.20 seconds
Epoch: [1][200/268]	Avg Loss 7.1218 Loss_id 6.4325 Loss_tri 0.9409 Time 22.21 seconds
Epoch: [1][220/268]	Avg Loss 7.0932 Loss_id 6.3887 Loss_tri 0.5540 Time 22.20 seconds
Epoch: [1][240/268]	Avg Loss 7.1295 Loss_id 6.2283 Loss_tri 0.7453 Time 22.23 seconds
Epoch: [1][260/268]	Avg Loss 7.0320 Loss_id 6.4381 Loss_tri 0.5423 Time 22.21 seconds
Epoch: [2][20/268]	Avg Loss 7.3692 Loss_id 6.3819 Loss_tri 0.6856 Time 28.36 seconds
Epoch: [2][40/268]	Avg Loss 6.9874 Loss_id 6.3186 Loss_tri 0.9124 Time 22.13 seconds
Epoch: [2][60/268]	Avg Loss 6.9114 Loss_id 6.2805 Loss_tri 0.7164 Time 22.22 seconds
Epoch: [2][80/268]	Avg Loss 6.8479 Loss_id 6.1580 Loss_tri 0.6129 Time 22.14 seconds
Epoch: [2][100/268]	Avg Loss 6.8626 Loss_id 6.2755 Loss_tri 0.9753 Time 22.13 seconds
Epoch: [2][120/268]	Avg Loss 6.8586 Loss_id 6.3100 Loss_tri 0.5726 Time 22.23 seconds
Epoch: [2][140/268]	Avg Loss 6.7981 Loss_id 6.3732 Loss_tri 0.4375 Time 22.18 seconds
Epoch: [2][160/268]	Avg Loss 6.8670 Loss_id 6.2612 Loss_tri 0.8341 Time 22.15 seconds
Epoch: [2][180/268]	Avg Loss 6.8238 Loss_id 6.3901 Loss_tri 0.3711 Time 22.18 seconds
Epoch: [2][200/268]	Avg Loss 6.7252 Loss_id 6.3312 Loss_tri 0.7013 Time 22.15 seconds
Epoch: [2][220/268]	Avg Loss 6.7339 Loss_id 6.2858 Loss_tri 0.4159 Time 22.17 seconds
Epoch: [2][240/268]	Avg Loss 6.7435 Loss_id 6.0153 Loss_tri 0.6533 Time 22.16 seconds
Epoch: [2][260/268]	Avg Loss 6.7421 Loss_id 6.3756 Loss_tri 0.3809 Time 22.09 seconds
Epoch: [3][20/268]	Avg Loss 7.1218 Loss_id 6.2948 Loss_tri 0.6674 Time 28.43 seconds
Epoch: [3][40/268]	Avg Loss 6.7045 Loss_id 6.1996 Loss_tri 0.7751 Time 22.18 seconds
Epoch: [3][60/268]	Avg Loss 6.6301 Loss_id 6.1348 Loss_tri 0.5712 Time 22.27 seconds
Epoch: [3][80/268]	Avg Loss 6.5727 Loss_id 6.0190 Loss_tri 0.3480 Time 22.16 seconds
Epoch: [3][100/268]	Avg Loss 6.6107 Loss_id 6.1450 Loss_tri 0.8182 Time 22.27 seconds
Epoch: [3][120/268]	Avg Loss 6.6220 Loss_id 6.2142 Loss_tri 0.3851 Time 22.19 seconds
Epoch: [3][140/268]	Avg Loss 6.5692 Loss_id 6.2870 Loss_tri 0.3182 Time 22.21 seconds
Epoch: [3][160/268]	Avg Loss 6.6244 Loss_id 6.1424 Loss_tri 0.4964 Time 22.21 seconds
Epoch: [3][180/268]	Avg Loss 6.6116 Loss_id 6.3354 Loss_tri 0.4288 Time 22.19 seconds
Epoch: [3][200/268]	Avg Loss 6.5172 Loss_id 6.2332 Loss_tri 0.5290 Time 22.20 seconds
Epoch: [3][220/268]	Avg Loss 6.4982 Loss_id 6.1806 Loss_tri 0.2727 Time 22.29 seconds
Epoch: [3][240/268]	Avg Loss 6.5553 Loss_id 5.8343 Loss_tri 0.4053 Time 22.19 seconds
Epoch: [3][260/268]	Avg Loss 6.5024 Loss_id 6.3026 Loss_tri 0.2745 Time 22.14 seconds
Epoch: [4][20/268]	Avg Loss 6.9278 Loss_id 6.1966 Loss_tri 0.4745 Time 28.52 seconds
Epoch: [4][40/268]	Avg Loss 6.5262 Loss_id 6.0657 Loss_tri 0.9262 Time 22.15 seconds
Epoch: [4][60/268]	Avg Loss 6.4313 Loss_id 5.9968 Loss_tri 0.5093 Time 22.20 seconds
Epoch: [4][80/268]	Avg Loss 6.3465 Loss_id 5.8824 Loss_tri 0.2676 Time 22.23 seconds
Epoch: [4][100/268]	Avg Loss 6.3729 Loss_id 5.9928 Loss_tri 0.7598 Time 22.19 seconds
Epoch: [4][120/268]	Avg Loss 6.4231 Loss_id 6.1167 Loss_tri 0.3594 Time 22.25 seconds
Epoch: [4][140/268]	Avg Loss 6.3427 Loss_id 6.1632 Loss_tri 0.1916 Time 22.17 seconds
Epoch: [4][160/268]	Avg Loss 6.3863 Loss_id 5.9920 Loss_tri 0.4283 Time 22.17 seconds
Epoch: [4][180/268]	Avg Loss 6.4102 Loss_id 6.2290 Loss_tri 0.2898 Time 22.18 seconds
Epoch: [4][200/268]	Avg Loss 6.3132 Loss_id 6.0961 Loss_tri 0.3727 Time 22.25 seconds
Epoch: [4][220/268]	Avg Loss 6.2854 Loss_id 6.0312 Loss_tri 0.2554 Time 22.24 seconds
Epoch: [4][240/268]	Avg Loss 6.3523 Loss_id 5.6453 Loss_tri 0.4734 Time 22.26 seconds
Epoch: [4][260/268]	Avg Loss 6.3496 Loss_id 6.1745 Loss_tri 0.3025 Time 22.18 seconds
Epoch: [5][20/268]	Avg Loss 6.7150 Loss_id 6.0728 Loss_tri 0.4482 Time 28.56 seconds
Epoch: [5][40/268]	Avg Loss 6.2974 Loss_id 5.8939 Loss_tri 0.7994 Time 22.18 seconds
Epoch: [5][60/268]	Avg Loss 6.2051 Loss_id 5.8108 Loss_tri 0.4402 Time 22.23 seconds
Epoch: [5][80/268]	Avg Loss 6.1320 Loss_id 5.6491 Loss_tri 0.3588 Time 22.11 seconds
Epoch: [5][100/268]	Avg Loss 6.1448 Loss_id 5.7444 Loss_tri 0.5312 Time 22.18 seconds
Epoch: [5][120/268]	Avg Loss 6.2358 Loss_id 5.9101 Loss_tri 0.3173 Time 22.14 seconds
Epoch: [5][140/268]	Avg Loss 6.1549 Loss_id 5.9809 Loss_tri 0.3605 Time 22.13 seconds
Epoch: [5][160/268]	Avg Loss 6.1542 Loss_id 5.7410 Loss_tri 0.4359 Time 22.15 seconds
Epoch: [5][180/268]	Avg Loss 6.1493 Loss_id 6.0244 Loss_tri 0.1812 Time 22.14 seconds
Epoch: [5][200/268]	Avg Loss 6.1034 Loss_id 5.8637 Loss_tri 0.6507 Time 22.18 seconds
Epoch: [5][220/268]	Avg Loss 6.0522 Loss_id 5.7856 Loss_tri 0.4242 Time 22.24 seconds
Epoch: [5][240/268]	Avg Loss 6.0825 Loss_id 5.2973 Loss_tri 0.4225 Time 22.20 seconds
Epoch: [5][260/268]	Avg Loss 6.1046 Loss_id 5.9147 Loss_tri 0.1074 Time 22.19 seconds
Extracting Gallery Feature...
Extracting Query Feature...
Computing CMC and mAP
Results ----------
testmAP: 2.8%
CMC curve
Rank-1  : 4.6%
Rank-5  : 11.2%
Rank-10 : 15.8%
Rank-20 : 22.8%
------------------
Extracting Gallery Feature...
Extracting Query Feature...
Computing CMC and mAP
Results ----------
testmAP: 4.1%
CMC curve
Rank-1  : 6.6%
Rank-5  : 18.8%
Rank-10 : 27.2%
Rank-20 : 38.5%
------------------
Epoch: [6][20/268]	Avg Loss 6.5033 Loss_id 5.8243 Loss_tri 0.6042 Time 28.28 seconds
Epoch: [6][40/268]	Avg Loss 6.0223 Loss_id 5.5315 Loss_tri 1.2510 Time 22.12 seconds
Epoch: [6][60/268]	Avg Loss 5.9529 Loss_id 5.4869 Loss_tri 0.7504 Time 22.14 seconds
Epoch: [6][80/268]	Avg Loss 5.7475 Loss_id 5.1187 Loss_tri 0.5390 Time 22.14 seconds
Epoch: [6][100/268]	Avg Loss 5.7492 Loss_id 5.2145 Loss_tri 0.8598 Time 22.20 seconds
Epoch: [6][120/268]	Avg Loss 5.9894 Loss_id 5.5206 Loss_tri 0.6046 Time 22.17 seconds
Epoch: [6][140/268]	Avg Loss 5.7860 Loss_id 5.5782 Loss_tri 0.5522 Time 22.17 seconds
Epoch: [6][160/268]	Avg Loss 5.8746 Loss_id 5.2571 Loss_tri 0.3679 Time 22.17 seconds
Epoch: [6][180/268]	Avg Loss 5.8493 Loss_id 5.5443 Loss_tri 0.5770 Time 22.12 seconds
Epoch: [6][200/268]	Avg Loss 5.7550 Loss_id 5.3734 Loss_tri 0.5996 Time 22.15 seconds
Epoch: [6][220/268]	Avg Loss 5.7444 Loss_id 5.1753 Loss_tri 0.5055 Time 22.16 seconds
Epoch: [6][240/268]	Avg Loss 5.7464 Loss_id 4.7037 Loss_tri 0.9066 Time 22.16 seconds
Epoch: [6][260/268]	Avg Loss 5.7731 Loss_id 5.3786 Loss_tri 0.5889 Time 22.21 seconds
Epoch: [7][20/268]	Avg Loss 6.1113 Loss_id 5.3637 Loss_tri 1.0863 Time 28.45 seconds
Epoch: [7][40/268]	Avg Loss 5.6047 Loss_id 4.9429 Loss_tri 2.0740 Time 22.17 seconds
Epoch: [7][60/268]	Avg Loss 5.4240 Loss_id 4.8200 Loss_tri 0.9700 Time 22.23 seconds
Epoch: [7][80/268]	Avg Loss 5.2228 Loss_id 4.4113 Loss_tri 0.4461 Time 22.19 seconds
Epoch: [7][100/268]	Avg Loss 5.3963 Loss_id 4.5222 Loss_tri 1.4489 Time 22.15 seconds
Epoch: [7][120/268]	Avg Loss 5.3943 Loss_id 4.8391 Loss_tri 1.0620 Time 22.15 seconds
Epoch: [7][140/268]	Avg Loss 5.1770 Loss_id 4.8354 Loss_tri 0.6292 Time 22.23 seconds
Epoch: [7][160/268]	Avg Loss 5.1823 Loss_id 4.4558 Loss_tri 0.8882 Time 22.21 seconds
Epoch: [7][180/268]	Avg Loss 5.0917 Loss_id 4.7449 Loss_tri 0.7310 Time 22.21 seconds
Epoch: [7][200/268]	Avg Loss 5.1937 Loss_id 4.6085 Loss_tri 1.3661 Time 22.15 seconds
Epoch: [7][220/268]	Avg Loss 5.0808 Loss_id 4.3535 Loss_tri 0.5471 Time 22.17 seconds
Epoch: [7][240/268]	Avg Loss 5.0022 Loss_id 3.7587 Loss_tri 0.9783 Time 22.20 seconds
Epoch: [7][260/268]	Avg Loss 5.0886 Loss_id 4.6216 Loss_tri 0.4839 Time 22.14 seconds
Epoch: [8][20/268]	Avg Loss 5.5589 Loss_id 4.6102 Loss_tri 0.8480 Time 28.54 seconds
Epoch: [8][40/268]	Avg Loss 4.7761 Loss_id 3.9514 Loss_tri 1.9516 Time 22.13 seconds
Epoch: [8][60/268]	Avg Loss 4.6295 Loss_id 3.8857 Loss_tri 1.5913 Time 22.18 seconds
Epoch: [8][80/268]	Avg Loss 4.4907 Loss_id 3.7671 Loss_tri 0.2051 Time 22.14 seconds
Epoch: [8][100/268]	Avg Loss 4.4875 Loss_id 3.6329 Loss_tri 1.9422 Time 22.17 seconds
Epoch: [8][120/268]	Avg Loss 4.7659 Loss_id 4.1858 Loss_tri 0.8945 Time 22.17 seconds
Epoch: [8][140/268]	Avg Loss 4.4291 Loss_id 4.0763 Loss_tri 0.5982 Time 22.17 seconds
Epoch: [8][160/268]	Avg Loss 4.5721 Loss_id 3.5459 Loss_tri 0.8260 Time 22.16 seconds
Epoch: [8][180/268]	Avg Loss 4.1023 Loss_id 3.7329 Loss_tri 0.3873 Time 22.20 seconds
Epoch: [8][200/268]	Avg Loss 4.2337 Loss_id 3.4984 Loss_tri 0.8021 Time 22.19 seconds
Epoch: [8][220/268]	Avg Loss 4.2412 Loss_id 3.6480 Loss_tri 0.3300 Time 22.20 seconds
Epoch: [8][240/268]	Avg Loss 4.4349 Loss_id 3.0273 Loss_tri 1.9626 Time 22.17 seconds
Epoch: [8][260/268]	Avg Loss 4.2440 Loss_id 3.7598 Loss_tri 0.2632 Time 22.22 seconds
Epoch: [9][20/268]	Avg Loss 4.8568 Loss_id 3.7389 Loss_tri 1.8060 Time 28.68 seconds
Epoch: [9][40/268]	Avg Loss 4.0392 Loss_id 3.2572 Loss_tri 1.7699 Time 22.10 seconds
Epoch: [9][60/268]	Avg Loss 3.7518 Loss_id 2.8902 Loss_tri 1.0120 Time 22.19 seconds
Epoch: [9][80/268]	Avg Loss 3.4155 Loss_id 2.9578 Loss_tri 0.1574 Time 22.20 seconds
Epoch: [9][100/268]	Avg Loss 3.4696 Loss_id 2.7389 Loss_tri 1.3331 Time 22.17 seconds
Epoch: [9][120/268]	Avg Loss 3.7437 Loss_id 3.5393 Loss_tri 0.2903 Time 22.22 seconds
Epoch: [9][140/268]	Avg Loss 3.3119 Loss_id 3.0862 Loss_tri 1.0462 Time 22.20 seconds
Epoch: [9][160/268]	Avg Loss 3.3996 Loss_id 2.8116 Loss_tri 0.8951 Time 22.21 seconds
Epoch: [9][180/268]	Avg Loss 3.3121 Loss_id 2.9180 Loss_tri 0.3940 Time 22.19 seconds
Epoch: [9][200/268]	Avg Loss 3.2323 Loss_id 2.5931 Loss_tri 0.7350 Time 22.20 seconds
Epoch: [9][220/268]	Avg Loss 3.4445 Loss_id 2.7643 Loss_tri 0.5146 Time 22.12 seconds
Epoch: [9][240/268]	Avg Loss 3.3399 Loss_id 2.3806 Loss_tri 1.1485 Time 22.16 seconds
Epoch: [9][260/268]	Avg Loss 3.3612 Loss_id 2.8948 Loss_tri 0.1441 Time 22.17 seconds
Epoch: [10][20/268]	Avg Loss 3.8747 Loss_id 2.6047 Loss_tri 1.0588 Time 28.79 seconds
Epoch: [10][40/268]	Avg Loss 3.2371 Loss_id 2.5586 Loss_tri 1.5640 Time 22.19 seconds
Epoch: [10][60/268]	Avg Loss 2.7206 Loss_id 2.0467 Loss_tri 0.4493 Time 22.22 seconds
Epoch: [10][80/268]	Avg Loss 2.5956 Loss_id 2.4630 Loss_tri 0.0000 Time 22.19 seconds
Epoch: [10][100/268]	Avg Loss 2.5326 Loss_id 2.1748 Loss_tri 1.4979 Time 22.17 seconds
Epoch: [10][120/268]	Avg Loss 2.9088 Loss_id 3.0295 Loss_tri 0.4687 Time 22.21 seconds
Epoch: [10][140/268]	Avg Loss 2.3123 Loss_id 2.0068 Loss_tri 0.3605 Time 22.20 seconds
Epoch: [10][160/268]	Avg Loss 2.4160 Loss_id 2.1439 Loss_tri 1.6683 Time 22.14 seconds
Epoch: [10][180/268]	Avg Loss 2.5320 Loss_id 2.0935 Loss_tri 0.6464 Time 22.25 seconds
Epoch: [10][200/268]	Avg Loss 2.2766 Loss_id 1.9123 Loss_tri 0.3488 Time 22.21 seconds
Epoch: [10][220/268]	Avg Loss 2.1554 Loss_id 1.8672 Loss_tri 0.1001 Time 22.22 seconds
Epoch: [10][240/268]	Avg Loss 2.1654 Loss_id 1.1615 Loss_tri 0.9347 Time 22.21 seconds
Epoch: [10][260/268]	Avg Loss 2.2672 Loss_id 2.0892 Loss_tri 0.3017 Time 22.22 seconds
Extracting Gallery Feature...
Extracting Query Feature...
Computing CMC and mAP
Results ----------
testmAP: 5.4%
CMC curve
Rank-1  : 8.3%
Rank-5  : 18.7%
Rank-10 : 25.3%
Rank-20 : 34.2%
------------------
Extracting Gallery Feature...
Extracting Query Feature...
Computing CMC and mAP
Results ----------
testmAP: 6.6%
CMC curve
Rank-1  : 10.3%
Rank-5  : 24.9%
Rank-10 : 33.5%
Rank-20 : 44.4%
------------------
Epoch: [11][20/268]	Avg Loss 2.6257 Loss_id 1.7974 Loss_tri 0.7637 Time 28.58 seconds
Epoch: [11][40/268]	Avg Loss 2.3871 Loss_id 2.1341 Loss_tri 1.9766 Time 22.10 seconds
Epoch: [11][60/268]	Avg Loss 2.0769 Loss_id 1.6484 Loss_tri 1.4593 Time 22.16 seconds
Epoch: [11][80/268]	Avg Loss 2.1000 Loss_id 2.1193 Loss_tri 0.2187 Time 22.17 seconds
Epoch: [11][100/268]	Avg Loss 2.0651 Loss_id 1.5455 Loss_tri 0.4389 Time 22.24 seconds
Epoch: [11][120/268]	Avg Loss 2.1872 Loss_id 2.4880 Loss_tri 0.3313 Time 22.19 seconds
Epoch: [11][140/268]	Avg Loss 1.7265 Loss_id 1.4010 Loss_tri 0.1840 Time 22.13 seconds
Epoch: [11][160/268]	Avg Loss 1.8536 Loss_id 1.5721 Loss_tri 0.0008 Time 22.17 seconds
Epoch: [11][180/268]	Avg Loss 1.6580 Loss_id 1.4732 Loss_tri 0.2554 Time 22.16 seconds
Epoch: [11][200/268]	Avg Loss 1.6060 Loss_id 1.3434 Loss_tri 0.4352 Time 22.13 seconds
Epoch: [11][220/268]	Avg Loss 1.6063 Loss_id 1.3387 Loss_tri 0.3505 Time 22.22 seconds
wandb: - 0.014 MB of 0.014 MB uploadedwandb: \ 0.014 MB of 0.014 MB uploadedwandb: | 0.014 MB of 0.014 MB uploadedwandb: / 0.014 MB of 0.014 MB uploadedwandb: - 0.022 MB of 0.046 MB uploadedwandb: \ 0.022 MB of 0.046 MB uploadedwandb: | 0.046 MB of 0.046 MB uploadedwandb: / 0.046 MB of 0.046 MB uploadedwandb: 
wandb: Run history:
wandb:    Avg Loss ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   Batch_idx ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñá‚ñÇ‚ñÑ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñá‚ñà‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñá‚ñÇ‚ñÑ‚ñÜ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñá‚ñÇ‚ñÖ‚ñá
wandb:       Epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:     Loss_id ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:    Loss_tri ‚ñà‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        Time ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     mAP_t2v ‚ñÅ‚ñÑ‚ñà
wandb:     mAP_v2t ‚ñÅ‚ñÖ‚ñà
wandb:  t2v-Rank-1 ‚ñÅ‚ñÑ‚ñà
wandb: t2v-Rank-20 ‚ñÅ‚ñÑ‚ñà
wandb:  v2t-Rank-1 ‚ñÅ‚ñÖ‚ñà
wandb: v2t-Rank-20 ‚ñÅ‚ñÜ‚ñà
wandb: 
wandb: Run summary:
wandb:    Avg Loss 1.60627
wandb:   Batch_idx 220
wandb:       Epoch 11
wandb:     Loss_id 1.33865
wandb:    Loss_tri 0.35046
wandb:        Time 22.21539
wandb:       epoch 10
wandb:     mAP_t2v 0.05437
wandb:     mAP_v2t 0.06573
wandb:  t2v-Rank-1 0.0829
wandb: t2v-Rank-20 0.18652
wandb:  v2t-Rank-1 0.10296
wandb: v2t-Rank-20 0.24868
wandb: 
wandb: üöÄ View run misty-blaze-2 at: https://wandb.ai/jwj1342/PoseReid/runs/9er94i1t
wandb: Ô∏è‚ö° View job at https://wandb.ai/jwj1342/PoseReid/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjY1NDkyNQ==/version_details/v0
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240308_092735-9er94i1t/logs
Traceback (most recent call last):
  File "trainer.py", line 112, in <module>
    optimizer.step()
  File "/root/miniconda3/lib/python3.8/site-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/torch/optim/sgd.py", line 144, in step
    F.sgd(params_with_grad,
  File "/root/miniconda3/lib/python3.8/site-packages/torch/optim/_functional.py", line 186, in sgd
    buf.mul_(momentum).add_(d_p, alpha=1 - dampening)
KeyboardInterrupt
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/root/miniconda3/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 268, in check_network_status
    self._loop_check_status(
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 224, in _loop_check_status
    local_handle = request()
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 792, in deliver_network_status
    return self._deliver_network_status(status)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 500, in _deliver_network_status
    return self._deliver_record(record)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 449, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/root/miniconda3/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/root/miniconda3/lib/python3.8/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 286, in check_stop_status
    self._loop_check_status(
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 224, in _loop_check_status
    local_handle = request()
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 784, in deliver_stop_status
    return self._deliver_stop_status(status)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 484, in _deliver_stop_status
    return self._deliver_record(record)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 449, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/root/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
